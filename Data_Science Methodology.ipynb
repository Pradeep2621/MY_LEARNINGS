{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eebd852-861b-4c8b-9343-e60aeb1cc349",
   "metadata": {},
   "source": [
    "# Final Assignment - Data science Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc40f32-effd-40f6-bc73-5c38c9a3c2ed",
   "metadata": {},
   "source": [
    "## ROLE - The Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b270e-b387-42e9-86b6-598c8276a51d",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "\n",
    "We are an email service provider with 10,000 business clients. Our selling point is security and efficiency.\n",
    "\n",
    "However, over the last six months, spammers have become much smarter. It used to be easy to spot spam—it was just bad grammar and 'You won a lottery' subject lines. Now, spammers are using sophisticated templates that look like real invoices or bank alerts.\n",
    "\n",
    "**The Impact:**\n",
    "\n",
    "- Lost Productivity: Our business clients are complaining that their employees spend 20 minutes every morning just deleting junk.\n",
    "\n",
    "- Churn Risk: Three major clients have threatened to cancel their contracts and move to Gmail if we don't fix this.\n",
    "\n",
    "- Volume: We receive 5 million emails a day. We cannot hire humans to check them (for privacy reasons and pure volume). We need a system that scales.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df3bf4-2853-4545-85f4-e394daea4888",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20cfb62-58b5-4e9e-b3ed-6d48bc64bb53",
   "metadata": {},
   "source": [
    "## ROLE - Data Scienctist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53953b-7366-424a-b023-3da37f9f2bac",
   "metadata": {},
   "source": [
    "Solving the problem using the **CRISP-DM** Methodology - (Cross Industry Standard Process for Data Mining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4785cb-92b5-4a21-b4ed-1c9252f6fc14",
   "metadata": {},
   "source": [
    "### Stage 1: Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a8d7a-d00b-407e-97c1-de0eeffe52c9",
   "metadata": {},
   "source": [
    "Before we even touch the data, we need to understand the business. We must identify the problem, the constraints, the goals, and the deliverables for the project. Essentially, we need to define what success looks like.\n",
    "\n",
    "In our problem statement, we saw the core issue: spam emails are getting mixed in with important emails. This directly affects user productivity and is causing a high rate of customer churn. Since the volume of incoming emails is massive, we can't solve this manually.\n",
    "\n",
    "Therefore, our goal isn't just identifying patterns; it is to help the client increase productivity and reduce churn risk.\n",
    "\n",
    "The critical constraint here is minimizing False Positives. We cannot risk flagging a real invoice or a legitimate email as spam. If a critical email gets moved to the spam folder, it could cause a direct business loss.\n",
    "\n",
    "Finally, the output we expect from the model is a binary classification: 0 for Safe and 1 for Spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd1f23-2d59-487d-9e04-c961297670cb",
   "metadata": {},
   "source": [
    "### Stage 2: Data Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e071240-4bc6-451a-aa4a-8e6c38d9599d",
   "metadata": {},
   "source": [
    "Once we have understood the business problem, we move to the second stage: Data Understanding.\n",
    "\n",
    "Here, we ask ourselves: What data do we actually have?\n",
    "\n",
    "The major dataset is the email logs from the client's server. To understand this, we need to pull that raw data and save it into our database for inspection.\n",
    "\n",
    "- We then look for specific patterns. What does a spam email actually look like?\n",
    "- We analyze the Subject Lines: Are there common triggers?\n",
    "- We examine the Body: What keywords appear most often? What is the structure of the text?\n",
    "- We check the Metadata: Is there a specific sender address? What time of day did these emails arrive?\n",
    "\n",
    "By asking these questions, we also discover problems with the data. The biggest issue we identify is that computers can't read language—they only understand numbers. We realize we will need to convert this text into tokens later. We also find 'dirty' data, such as empty emails or broken characters.\n",
    "\n",
    "The outcome of this stage is crucial. All the insights and problems we discover here become the input for the next stage: Data Preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff083e73-0150-458a-aedb-3f460bac37e6",
   "metadata": {},
   "source": [
    "### Stage 3: Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec95187-ec0c-4b22-bbb6-0f29782e72ed",
   "metadata": {},
   "source": [
    "In my three weeks of learning Data Science, I’ve heard countless times that this stage consumes the most time in any project. It is the 'janitor work' of the process.\n",
    "\n",
    "Based on the insights we gathered in the previous stage, we now practically apply those fixes to the data.\n",
    "\n",
    "First, we clean the data. Since we are dealing with emails, they often come full of HTML tags (like <div> or <br>). The first step is to strip these tags out so we are left with just the plain text.\n",
    "\n",
    "Next, we handle inconsistency. Emails are written in all kinds of formats—some are all caps, some are lowercase, some are mixed. To a computer, 'FREE' and 'free' look like two different words. So, I will convert everything into a universal lowercase format to ensure consistency.\n",
    "\n",
    "Finally, as we established earlier, computers don't understand language. We need to tokenize the emails. I will break every sentence down into individual words—or 'tokens'—and store them in a list. A raw email is now transformed into a clean list of keywords like ['lottery', 'winner', 'click', 'here'] or ['invoice', 'cash'].\n",
    "\n",
    "This prepared data is now ready to be fed into the analysis. It becomes the clean input for our next stage: Modeling.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1365be0-9fc2-4ef8-ba68-0307cb3ab010",
   "metadata": {},
   "source": [
    "### Stage 4: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e50f0-ee7f-4fea-b876-fcd4e41b37f7",
   "metadata": {},
   "source": [
    "\n",
    "I’ll be honest—I haven't built a model practically yet. But through this course, I’ve learned that the most critical step isn't just writing code; it's selecting the appropriate model for the specific problem we are solving.\n",
    "\n",
    "Why Logistic Regression? In our first stage (Business Understanding), we defined that we need a simple 'Yes' or 'No' output: Is this Spam (1) or Safe (0)? We also need to know the conviction—how confident is the model in its decision?\n",
    "\n",
    "Based on my learning, Logistic Regression fits this perfectly. Why? Because unlike other models, it outputs a probability. It doesn't just guess; it tells us, 'I am 80% sure this is spam.' This aligns exactly with our business need to minimize errors.\n",
    "\n",
    "The Process: We take our tens of thousands of cleaned, tokenized emails and split them. A common standard is a 75/25 split:\n",
    "\n",
    "- 75% is used for Training (Teaching the model).\n",
    "- 25% is hidden away for Testing (Checking the model later).\n",
    "\n",
    "How it Learns: During training, the model 'crunches' the data.\n",
    "\n",
    "- It learns that words like 'Meeting,' 'Project,' or 'Mom' usually appear in safe emails, pulling the probability down toward 0.\n",
    "- In parallel, it learns that terms like 'Wire Transfer,' 'Lottery,' or 'Click Here' push the probability up toward 1 (Spam).\n",
    "\n",
    "By the end of this stage, we have a trained model that can look at a new email and calculate the probability of it being junk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e79f65-bb42-417a-9164-c2740dab3013",
   "metadata": {},
   "source": [
    "### Stage 5: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4fb3b-0675-440b-acda-a1caa0e42dfd",
   "metadata": {},
   "source": [
    "We have reached the fifth stage: Evaluation. This is arguably the most important safety check in the entire Data Science lifecycle.\n",
    "\n",
    "Why? Because before we deploy this model into the real world, we need to prove it works.\n",
    "\n",
    "Remember the 25% of data we held back during the previous stage? That data is now our 'Exam Paper.' The model has never seen these emails before. We feed this test data into the model and compare its predictions against the real answers.\n",
    "\n",
    "What are we looking for? First, we look at Performance: If the model catches 90% to 98% of the spam, that’s a great start.\n",
    "\n",
    "But—and this is critical—we must look back at our Business Constraints. In Stage 1, we explicitly stated that we cannot afford to lose important emails. So, I have to ask: 'Did the model accidentally flag an email from the CEO as spam?'\n",
    "\n",
    "If the answer is 'Yes,' then even with 98% accuracy, the model is a failure. We cannot deploy it.\n",
    "\n",
    "The Iterative Loop: If we fail this check, we stop. We don't deploy. Instead, we go back to the Modeling or even Data Preparation stage to fix the issue. We iterate through these steps again and again until we get a model that is both accurate and safe.\n",
    "\n",
    "Only when the model meets the criteria we defined in the beginning do we give the green light for the final stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f2530-f485-4b81-ac68-4869db921168",
   "metadata": {},
   "source": [
    "### Stage 6: Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab281ac9-a2f9-49c6-8870-3cfe4d94649f",
   "metadata": {},
   "source": [
    "Finally, we arrive at Stage 6: Deployment.\n",
    "\n",
    "Once we have confirmed all the critical outcomes in the Evaluation stage, we are ready to go live.\n",
    "The Integration: For this project, the model needs to sit directly on the client's Email Server.\n",
    "\n",
    "Here is how it works in production:\n",
    "\n",
    "- Every email that arrives at the server passes through our model first.\n",
    "- The model flags it: 0 (Safe) or 1 (Spam).\n",
    "- If it’s Safe, it goes to the Inbox. If it’s Spam, it is routed to the Junk folder.\n",
    "\n",
    "A Critical Note on Privacy: We must remember we are dealing with private, sensitive user data. We need to ensure that every email is encrypted during this process so that no private information is leaked while the model is reading it.\n",
    "\n",
    "The Feedback Loop: But here is the truth: Deployment is not the end of a Data Science project. In fact, this is where the real work starts.\n",
    "\n",
    "Once the model is in the real world, we must continuously collect feedback:\n",
    "\n",
    "Are users manually moving emails out of the Spam folder? (That means our model made a mistake).\n",
    "\n",
    "Are spammers using new tricks?\n",
    "\n",
    "This new data might reveal new variables we missed earlier—like spammers using emojis or specific colors to trick the system. This new information flows right back to Stage 1 (Business Understanding), and the cycle begins again. We constantly update the model to keep it smarter than the spammers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81c42e-4d7a-44f2-9d06-0c87768e7b9c",
   "metadata": {},
   "source": [
    "# Author\n",
    "Prdeep Buchadi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee41a3c-d32b-49ca-93d4-f2f4a1cd800e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cda1fbb-17c0-4b34-a157-763b2f931450",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
